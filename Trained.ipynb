{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4UBuvyB7LRB"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import pickle\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = '/content/CV-Parsing-using-Spacy-3-master.zip'\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # List contents of the zip file\n",
        "    zip_contents = zip_ref.namelist()\n",
        "\n",
        "    # Check if the 'train/train_data.pkl' file exists in the zip contents\n",
        "    if 'CV-Parsing-using-Spacy-3-master/data/training/train_data.pkl' in zip_contents:\n",
        "        # Open the pickle file and load the data\n",
        "        with zip_ref.open('CV-Parsing-using-Spacy-3-master/data/training/train_data.pkl') as pickle_file:\n",
        "            train_data = pickle.load(pickle_file)\n",
        "            # Access the first item in the loaded data\n",
        "            print(train_data[0])\n",
        "    else:\n",
        "        print(\"train_data.pkl not found in the zip file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpjCQPrw8cj2",
        "outputId": "941f5300-53fe-4b6d-ae59-d3b3ceb4e602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/', {'entities': [(1749, 1755, 'Companies worked at'), (1696, 1702, 'Companies worked at'), (1417, 1423, 'Companies worked at'), (1356, 1793, 'Skills'), (1209, 1215, 'Companies worked at'), (1136, 1248, 'Skills'), (928, 932, 'Graduation Year'), (858, 889, 'College Name'), (821, 856, 'Degree'), (787, 791, 'Graduation Year'), (744, 750, 'Companies worked at'), (722, 742, 'Designation'), (658, 664, 'Companies worked at'), (640, 656, 'Designation'), (574, 580, 'Companies worked at'), (555, 573, 'Designation'), (470, 493, 'Companies worked at'), (444, 469, 'Designation'), (308, 314, 'Companies worked at'), (234, 240, 'Companies worked at'), (175, 198, 'Companies worked at'), (93, 137, 'Email Address'), (39, 48, 'Location'), (13, 38, 'Designation'), (0, 12, 'Name')]})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank('en')\n",
        "\n",
        "def train_model(train_data):\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe('ner', last = True)\n",
        "\n",
        "    for _, annotation in train_data:\n",
        "        for ent in annotation['entities']:\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(10):\n",
        "            print(\"Statring iteration \" + str(itn))\n",
        "            random.shuffle(train_data)\n",
        "            losses = {}\n",
        "            index = 0\n",
        "            for text, annotations in train_data:\n",
        "                try:\n",
        "                    nlp.update(\n",
        "                        [text],  # batch of texts\n",
        "                        [annotations],  # batch of annotations\n",
        "                        drop=0.2,  # dropout - make it harder to memorise data\n",
        "                        sgd=optimizer,  # callable to update weights\n",
        "                        losses=losses)\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "\n",
        "            print(losses)"
      ],
      "metadata": {
        "id": "RQu-piNQ-GjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import random\n",
        "from spacy.training.example import Example\n",
        "\n",
        "# Create a blank spaCy NER model\n",
        "nlp = spacy.blank('en')\n",
        "\n",
        "def train_model(train_data):\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.add_pipe('ner')\n",
        "    else:\n",
        "        ner = nlp.get_pipe('ner')\n",
        "\n",
        "    for _, annotations in train_data:\n",
        "        for ent in annotations['entities']:\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "\n",
        "    with nlp.disable_pipes(*other_pipes):\n",
        "        optimizer = nlp.begin_training()\n",
        "\n",
        "        for itn in range(10):  # You can adjust the number of iterations\n",
        "            print(\"Starting iteration \" + str(itn))\n",
        "            random.shuffle(train_data)\n",
        "            losses = {}\n",
        "            for text, annotations in train_data:\n",
        "                doc = nlp.make_doc(text)\n",
        "                example = Example.from_dict(doc, annotations)\n",
        "                nlp.update([example], drop=0.2, losses=losses)\n",
        "\n",
        "            print(losses)\n",
        "\n",
        "# Your training data with various entities\n",
        "train_data = [\n",
        "    (\"Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/\",\n",
        "    {'entities': [\n",
        "        (0, 15, 'Name'),\n",
        "        (16, 43, 'Designation'),\n",
        "        (44, 76, 'Location'),\n",
        "        (77, 94, 'Email Address'),\n",
        "        (95, 140, 'Links'),\n",
        "        (141, 162, 'Skills'),\n",
        "        (163, 196, 'Companies worked at'),\n",
        "        (197, 211, 'Years of Experience'),\n",
        "        (212, 237, 'Companies worked at'),\n",
        "        (238, 255, 'Designation'),\n",
        "        (256, 279, 'Companies worked at'),\n",
        "        (280, 297, 'Years of Experience'),\n",
        "        (298, 318, 'Designation'),\n",
        "        (319, 345, 'Companies worked at'),\n",
        "        (346, 372, 'Years of Experience'),\n",
        "        (373, 395, 'Designation'),\n",
        "        (396, 418, 'Companies worked at'),\n",
        "        (419, 445, 'Years of Experience'),\n",
        "        (446, 468, 'Designation'),\n",
        "        (469, 493, 'Companies worked at'),\n",
        "        (494, 518, 'Years of Experience'),\n",
        "        (519, 541, 'Designation'),\n",
        "        (542, 569, 'Companies worked at'),\n",
        "        (570, 593, 'Years of Experience'),\n",
        "        (594, 616, 'Designation'),\n",
        "        (617, 638, 'Companies worked at'),\n",
        "        (639, 665, 'Years of Experience'),\n",
        "        (666, 688, 'Designation'),\n",
        "        (689, 718, 'Companies worked at'),\n",
        "        (719, 741, 'Years of Experience'),\n",
        "        (742, 765, 'Designation'),\n",
        "        (766, 791, 'Companies worked at'),\n",
        "        (792, 817, 'Years of Experience'),\n",
        "        (818, 843, 'Designation'),\n",
        "        (844, 869, 'Companies worked at'),\n",
        "        (870, 894, 'Years of Experience'),\n",
        "        (895, 921, 'Designation'),\n",
        "        (922, 946, 'Companies worked at'),\n",
        "        (947, 971, 'Years of Experience'),\n",
        "        (972, 996, 'Designation'),\n",
        "        (997, 1020, 'Companies worked at'),\n",
        "        (1021, 1044, 'Years of Experience'),\n",
        "        (1045, 1067, 'Designation'),\n",
        "        (1068, 1096, 'Companies worked at'),\n",
        "        (1097, 1119, 'Years of Experience'),\n",
        "        (1120, 1141, 'Designation'),\n",
        "        (1142, 1170, 'Companies worked at'),\n",
        "        (1171, 1193, 'Years of Experience'),\n",
        "        (1194, 1214, 'Designation'),\n",
        "        (1215, 1240, 'Companies worked at'),\n",
        "        (1241, 1265, 'Years of Experience'),\n",
        "        (1266, 1286, 'Designation'),\n",
        "        (1287, 1320, 'Companies worked at'),\n",
        "        (1321, 1346, 'Years of Experience'),\n",
        "        (1347, 1371, 'Designation'),\n",
        "        (1372, 1414, 'Education'),\n",
        "        (1415, 1450, 'College Name'),\n",
        "        (1451, 1470, 'Location'),\n",
        "        (1471, 1487, 'Graduation Year'),\n",
        "        (1488, 1514, 'Links'),\n",
        "        (1515, 1549, 'Skills'),\n",
        "        (1550, 1571, 'Tools'),\n",
        "        (1572, 1593, 'Web Technologies'),\n",
        "        (1594, 1618, 'Operating Systems'),\n",
        "        (1619, 1654, 'Version Control System'),\n",
        "        (1655, 1684, 'Databases'),\n",
        "        (1685, 1707, 'Middleware'),\n",
        "        (1708, 1733, 'Product FLEXCUBE')\n",
        "    ]}),\n",
        "    # Add more data points with different entities here...\n",
        "]\n",
        "\n",
        "# Train the NER model\n",
        "train_model(train_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "NpT5NnQa-Knr",
        "outputId": "e1424b05-d7dc-428a-e629-0ac671eb2880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Govardhana K Senior Software Engineer  Bengaluru, ...\" with entities \"[(0, 15, 'Name'), (16, 43, 'Designation'), (44, 76...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the `debug data` command to validate your JSON-formatted training data. For details, run:\npython -m spacy debug data --help",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-aa8524af1559>\u001b[0m in \u001b[0;36m<cell line: 111>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;31m# Train the NER model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-aa8524af1559>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_data)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;31m# ignore statements are used here because mypy ignores hasattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"update\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m                 \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.update\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser._init_gold_batch\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/_parser_internals/transition_system.pyx\u001b[0m in \u001b[0;36mspacy.pipeline._parser_internals.transition_system.TransitionSystem.get_oracle_sequence_from_state\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the `debug data` command to validate your JSON-formatted training data. For details, run:\npython -m spacy debug data --help"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.to_disk('nlp_model')"
      ],
      "metadata": {
        "id": "BLh5tXTs-hbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_model = spacy.load('nlp_model')"
      ],
      "metadata": {
        "id": "J1OplXy6-mtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "BNrY4alV-m9j",
        "outputId": "b1bc7558-3127-4e55-cd6b-75ea4fbe2f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Suresh Kanagala Architecture SharePoint/Office 365 /Azure cloud/.Net  Hyderabad, Telangana - Email me on Indeed: indeed.com/r/Suresh- Kanagala/04b36892f9d2e2eb  Looking for challenging position  WORK EXPERIENCE  Technical Architect (Manager C2)  -  August 2015 to Present  Senior Professional Technology Analyst  CSC India -  September 2005 to August 2015  Consultant  IBM -  December 2004 to September 2005  Consultant Infosys from Modus Systems -Tester  -  June 2004 to December 2004  Associate consultant  CMC -  July 2003 to June 2004  EDUCATION  Month/Year Format  Tech lead -  Hyderabad, Telangana  September 2016 to May 2017  M.C.A  affiliated college of Andhra University  2002  https://www.indeed.com/r/Suresh-Kanagala/04b36892f9d2e2eb?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Suresh-Kanagala/04b36892f9d2e2eb?isid=rex-download&ikw=download-top&co=IN   B.Sc in Maths, Physics and Computers  Nagarjuna university  1999  SKILLS  .NET (Less than 1 year), ASP (Less than 1 year), DATABASE (Less than 1 year), MS SQL SERVER (Less than 1 year), SQL (Less than 1 year)  LINKS  http://www.linkedin.com/in/sureshkanagala  ADDITIONAL INFORMATION  Operating Systems Windows and Unix Configuration management tools TFS and VSTS Programming Languages VB, ASP, VB.net, C#, JavaScript, Jquery and Angular JS (Starter), CRM Frontend HTML and .Net Middleware MVC and WCF Database SQL Server and Oracle Content Migration tools Metalogix and Sharegate Automation PowerShell and VSTS  DOMAIN EXPERIENCE Insurance 10 Years Engineering 3 Years Banking 2.5 Years  http://www.linkedin.com/in/sureshkanagala'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp_model(train_data[0][0])\n",
        "for ent in doc.ents:\n",
        "    print(f'{ent.label_.upper():{30}}- {ent.text}')"
      ],
      "metadata": {
        "id": "IU_4wJyU-nGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbm30A1K-ymC",
        "outputId": "02d171b8-4dec-4c6e-fdc6-6e9795ad462e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.8-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.7 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.8 PyMuPDFb-1.23.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "\n",
        "fname = '/content/CV.pdf'\n",
        "doc = fitz.open(fname)\n",
        "\n",
        "text = \"\"\n",
        "for page in doc:\n",
        "    text += page.get_text()\n",
        "\n",
        "# Join text without line breaks\n",
        "tx = \" \".join(text.split('\\n'))\n",
        "print(tx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17Zoqdp9_Fqc",
        "outputId": "53c14b0e-cd16-4381-cb9c-73b31ccb7075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ABOUT ME A reliable candidate who studied Mechanical Engineering and has hands-on experience in Machine Learning and Deep Learning applying for software debug intern in Artiﬁcial Intelligence to expand skills and gain valuable real- world experience.   WORK EXPERIENCE Workshop Intern  Karachi Shipyard & Engineering Works [ 15/08/2022 – 15/08/2022 ]  City: Karachi  Country: Pakistan  Visits: • Practical knowledge of lathe machine (facing, boring, milling, turning, cutting, and drilling). • Knowledge of types of welding (TIG. MIG, SAW, SMAW). • Knowledge of welding positions (1G-6G, 1F-4F). • Knowledge of lab testing (Tensile, Hardness, Fatigue, Buckling). • Knowledge of furnaces (Gas & Electrical both). • Understanding of engineering drawing. Mechanical Engineering Intern  Peoples Steel Mill [ 15/10/2022 – 24/10/2022 ]  City: Karachi  Country: Pakistan  Visits: • M-Shop (Continuous casting, Ingot casting). • Q-Shop (Bar Rolling Mill). • N-Shop (Slabbing and Blooming Mill). • R-3 Shop (Press Forging Shop). • WTP (Water Treatment Plant). • QAD (Quality Assurance Department). Data Science Trainee  British Airways [ 07/12/2022 – 07/01/2023 ]  City: Karachi  Country: Pakistan  Haﬁz Hassan Mustafa  Nationality: Pakistani  Date of birth: 03/12/2000           Phone number: (+92) 3212712753  Email address: hassanqureshi700@gmail.com   LinkedIn: https://www.linkedin.com/in/haﬁz-hassan-mustafa-692b391b4   Home: Mir Ayub Khan Road Nazir Bibi Building 1st Floor Flat #3 Ranchor Line Ramswami, South Karachi, 74400 Karachi (Pakistan)   Tasks: • Web scraping to gain company insights. • Predicting customer buying behavior. AI & Data Science Trainee  Sayabidevs Software House [ 24/01/2023 – 25/02/2023 ]  City: Karachi  Country: Pakistan  Tasks: • Python Chatbot. • Sales Predictor. • Recommendation System. Deep Learning Fellow  Bytewise Limited [ 01/03/2023 – 01/06/2023 ]  City: Karachi  Country: Pakistan  Tasks: • Having knowledge of all Machine learning algorithms. Exploratory data analysis (EDA). • Missing Values and data cleaning. • Data Preprocessing techniques. • Feature Engineering. • Feature Selection. AI Engineer  CGD Consulting [ 12/08/2023 – Current ]  City: Karachi  Country: Pakistan  - Scraping and Automation. - Langchain & LLModels. - AI Law Consultant. - OPENAI Chatbots. - OCR. - Autogen (Project based on user proxy and agent.) EDUCATION AND TRAINING Bachelors of Engineering (Mechanical)  DHA Suﬀa University [ 24/09/2019 – 21/07/2023 ]  City: Karachi  Country: Pakistan  Website: https://www.dsu.edu.pk/  Field(s) of study: Mechanical Engineering  • Final Year Project (Design and Fabrication of Hubless Drive System). • Runner Up of Data Science Competition (Spectrum Event). • 2nd Position in Stable LM 3B 24-Hour International Hackathon (lablab.ai). LANGUAGE SKILLS  Mother tongue(s): Urdu  Other language(s):  English  LISTENING C1  READING C2  WRITING C2   SPOKEN PRODUCTION B2  SPOKEN INTERACTION C1   Levels: A1 and A2: Basic user; B1 and B2: Independent user; C1 and C2: Proﬁcient user DIGITAL SKILLS  Machine Learing /  Deep Learning, /  ARTIFICIAL INTELLIGENCE /  Experience in MATLAB, python, and R / Power BI/Power Pivot /  Data Visualization Tableau (Good Standing) /  Pytorch,Tensorﬂow /  Python, automation scripts, Requests, Selenium libraries /  Python ML and NLP libraries: Panda, Numpy, Scipy, Scikit-learn, Gensim, Flair, Spacy, TF Hub /  Database : MySQL(basic) /  Begginer HTML/CSS /  Frameworks & Libraries: OpenCV, Sci-kit learn, NumPy, Pandas, SciPy, Matplotlib. /  Basic OpenCV /  Python - statistical learning (Sklearn) /  Google (Google Docs, Google Drive, Google Slides, Google Sheets, Google Forms) /  Langchain /  LLM /  Autogen / OpenAI GPT2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp_model(tx)\n",
        "\n",
        "# Initialize variables to store extracted details\n",
        "person_name = \"\"\n",
        "email = \"\"\n",
        "phone = \"\"\n",
        "country = \"\"\n",
        "designation = \"\"\n",
        "other_details = []\n",
        "\n",
        "# Extract named entities and categorize information\n",
        "for entity in doc.ents:\n",
        "    if entity.label_ == \"PERSON\" and not person_name:\n",
        "        person_name = entity.text\n",
        "    elif entity.label_ == \"EMAIL\" and not email:\n",
        "        email = entity.text\n",
        "    elif entity.label_ == \"PHONE\" and not phone:\n",
        "        phone = entity.text\n",
        "    elif entity.label_ == \"GPE\" and not country:  # GPE represents geopolitical entities (countries)\n",
        "        country = entity.text\n",
        "    elif entity.label_ == \"TITLE\" and not designation:\n",
        "        designation = entity.text\n",
        "    else:\n",
        "        other_details.append((entity.text, entity.label_))\n",
        "\n",
        "# Display profile information\n",
        "print(\"Profile:\")\n",
        "print(f\"Person Name: {person_name}\")\n",
        "print(f\"Email: {email}\")\n",
        "print(f\"Phone: {phone}\")\n",
        "print(f\"Country: {country}\")\n",
        "print(f\"Designation: {designation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGAqS6qO_Ftp",
        "outputId": "856793f0-03e3-4cab-bfb5-5916372abde1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profile:\n",
            "Person Name: \n",
            "Email: \n",
            "Phone: \n",
            "Country: \n",
            "Designation: \n"
          ]
        }
      ]
    }
  ]
}