{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORB-_RFqLbQ3",
        "outputId": "3f19909b-7724-411d-c47c-f2b2e5672dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
            "  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
            "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "Installing collected packages: cloudpathlib, weasel, spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.7.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpathlib-0.16.0 spacy-3.7.2 weasel-0.3.4\n",
            "2024-01-09 20:04:10.299700: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-09 20:04:10.299768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-09 20:04:10.301806: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-09 20:04:10.309243: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-09 20:04:11.380844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.6.0\n",
            "    Uninstalling en-core-web-sm-3.6.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.6.0\n",
            "Successfully installed en-core-web-sm-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "2024-01-09 20:04:23.390953: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-09 20:04:23.391014: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-09 20:04:23.391910: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-09 20:04:23.396927: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-09 20:04:24.486971: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "2024-01-09 20:04:37.641194: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-09 20:04:37.641253: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-09 20:04:37.642152: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-09 20:04:37.647147: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-09 20:04:38.626589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "! pip install -U spacy\n",
        "# ! python -m spacy download en_core_web_sm\n",
        "# ! python -m spacy download en_core_web_md\n",
        "! python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VP6Y7G-LqDf",
        "outputId": "19e1d262-7c53-4dc3-c570-30f0443c9c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Noun phrases: ['Sebastian Thrun', 'self-driving cars', 'Google', 'few people', 'the company', 'him', 'I', 'you', 'very senior CEOs', 'major American car companies', 'my hand', 'I', 'Thrun', 'an interview', 'Recode']\n",
            "Verbs: ['start', 'work', 'drive', 'take', 'tell', 'shake', 'turn', 'talk', 'say']\n",
            "Sebastian Thrun PERSON\n",
            "Google ORG\n",
            "2007 DATE\n",
            "American NORP\n",
            "Thrun PERSON\n",
            "Recode ORG\n",
            "earlier this week DATE\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load English tokenizer, tagger, parser and NER\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process whole documents\n",
        "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
        "        \"Google in 2007, few people outside of the company took him \"\n",
        "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
        "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
        "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
        "        \"this week.\")\n",
        "doc = nlp(text)\n",
        "\n",
        "# Analyze syntax\n",
        "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
        "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
        "\n",
        "# Find named entities, phrases and concepts\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load English tokenizer, tagger, parser and NER\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "doc = nlp(\"Manchester United was founded in 1878 as Newon Heath in Manchester, England\")\n",
        "# Find named entities, phrases and concepts\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)\n",
        "# spacy.displacy.serve(doc, style='ent')\n",
        "# spacy.displacy.serve(doc, style='dep')\n",
        "\n",
        "# http://localhost:5000/"
      ],
      "metadata": {
        "id": "QkL7GmlYa9jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x6rULmcfert3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkILWKRkxo5H",
        "outputId": "7ecbd875-56bc-44ac-9e59-d92f2badb046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Details:\n",
            "Person Name: ['Sebastian Thrun', 'Adam Cooper San Francisco']\n",
            "Locations: ['US', 'Thrun', 'Pakistan']\n",
            "Organizations: ['Google']\n",
            "Language: []\n",
            "Dates: ['2007', '2 Years Employment History:', 'earlier this week']\n"
          ]
        }
      ],
      "source": [
        "# TESTING\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Process whole documents\n",
        "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
        "        \"Google in 2007, few people outside of the company took him \"\n",
        "        \"Email: hassanqureshi700@gmail.com \"\n",
        "        \"Phone: 0321-2712753 \"\n",
        "        \"Designation: AI Engineer. \"\n",
        "        \"Adam Cooper \"\n",
        "        \"San Francisco, US \"\n",
        "        \"America\"\n",
        "        \"Skills: Python, Designing, Cooking \"\n",
        "        \"Work Experience: 2 Years \"\n",
        "        \"Employment History: Bytewise Ltd \"\n",
        "        \"Deep Learning Fellow \"\n",
        "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
        "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
        "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
        "        \"this week in english Pakistan.\")\n",
        "doc = nlp(text)\n",
        "\n",
        "# Initialize variables to store extracted details\n",
        "person_name = []\n",
        "locations = []\n",
        "organizations = []\n",
        "language = []\n",
        "dates_and_time = []\n",
        "\n",
        "# Extract named entities and categorize information\n",
        "for entity in doc.ents:\n",
        "    if entity.label_ == \"PERSON\":\n",
        "        person_name.append(entity.text)\n",
        "    elif entity.label_ == \"GPE\":\n",
        "        locations.append(entity.text)\n",
        "    elif entity.label_ == \"ORG\":\n",
        "        organizations.append(entity.text)\n",
        "    elif entity.label_ == \"LANGUAGE\":\n",
        "        language.append(entity.text)\n",
        "    elif entity.label_ in [\"DATE\", \"TIME\"]:\n",
        "        dates_and_time.append(entity.text)\n",
        "\n",
        "# Display extracted details\n",
        "print(\"Extracted Details:\")\n",
        "print(\"Person Name:\", person_name)\n",
        "print(\"Locations:\", locations)\n",
        "print(\"Organizations:\", organizations)\n",
        "print(\"Language:\", language)\n",
        "print(\"Dates:\", dates_and_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXxxZrGGZQt4",
        "outputId": "ce390a53-93d7-45ec-e616-52785ac74761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "! pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CS5JWVYZQyK"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "\n",
        "# Open the PDF file\n",
        "# reader = PdfReader(\"Geneva-Resume-Template-Retro-Simple.pdf\")\n",
        "# reader = PdfReader(\"New-York-Resume-Template-Creative.pdf\")\n",
        "reader = PdfReader(\"2023_Curriculum Vitae_EN Version 1.pdf\")\n",
        "\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    text += page.extract_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvOX8En8ZpDt",
        "outputId": "6a5bb26b-69ea-4e3a-d380-7d08337e9b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "_________________________\n",
            "WORK EXPERIENCE 2016-2022 Professional Manager / Designer 7y 4m 2016-2021 IT Coordinator / Designer 6y 4m 2013-2016 Designer / Developer 3y 4m 2010-2012 IT Coordinator / Designer 1y 10m 2008-2008 IT consultant  CompTIA A +  0y 7m 2007-2008 Developer / Designer 0y 4m KAMAL S.M. AHMAD, BORN 1972 EXPERT IN IT & DESIGN SOLUTIONS | WORK EXPERIENCE 29 YEARS\n",
            "VOLUNTEER EXPERIENCE -IT Project Manager -Project Coordinator -Network Technical -Video-editing, ﬁnal cut, adobe Premiere, Adobe After effects.  -4D Cinema -PHP , JS, 4D, IONIC, -dimension, HTML, CSS -Adobe Photoshop,  Illustrator, Indesign.CERTIFICATES -Apple Support Professional (ACSP) -Apple System Administrator (ACSA) -Apple Certiﬁed Technical Coordinator -Apple Certiﬁed Specialist Directory Services -Microsoft Certiﬁed Technology Specialist (MCTS) -Apple Sales Training Gold certiﬁcate -CompTia A+ Essentials and IT-Technician Essentials -Apple Mac OS X server Essentials Certiﬁcate -ASP Certiﬁed at Toshiba, repair of laptopsEDUCATION -Leadership -Project Management  -Novell CNA Certiﬁcation -Web/Graphic design -ADB and terminal  -Trade and Business -Development -Quality Education -Server eductions -CNC and FMS-operator COMPETENCE -PHP , Javascript, CSS, HTML -Cinema 4d, -Excel, Word, Powerpoint, Outlook,  -Pages, Numbers, Mysql -Adobe Illustrator, Adobe Photoshop, Adobe Indesign, Final cut X Pro, Premiere, Adobe Effects, -Ionic mobile apps -4D dimension, Filemaker pro etc.SECTOR KNOWLEDGE -Design and Webbdesign -IT Coordinator -IT Manager -Banking -Sales -Developing -Media -MarketingINTRUDUCTION As a seasoned professional with 29 years of experience in both staff and managerial roles across international markets such as Sweden, Turkey, and Jordan, I boast ﬂuency in Swedish, English, and Arabic. I have led developer teams in different countries and bring expertise in IT technology, graphic design, video advertising, smart IT solutions, and more. With a background in frontend development using ReactJS, I am well-versed in the latest industry standards and technologies. Holding certiﬁcations as an IT Coordinator, Project Manager, and Quality Manager, I am seeking a managerial position to utilize my skills and drive success. I have multiple technical certiﬁcations including Apple Support Professional (ACSP), Microsoft Certiﬁed Technology Specialist (MCTS), and CompTIA A+ Essentials among others, making me well equipped to tackle any challenge.LANGUAGES Swedish Professional English Elementary Arabic Elementary\n",
            "TECHNICAL SKILLS Graphic designer 11y 10m Developer   10y 8m Freelancer  6y 4m Leadership 5y 3m Professional Manager 5y 1m Network administrator 3y 3m CNC and FMS Operator 0y 9m\n",
            "PERSONAL QUALIFICATIONS -Professional Manager -Project manager -Consulting -Developing -Designer  -Video edition -SEO and Social Media WORKED FOR -Arena AB -IMS AB -Munkeby Systems AB -Custoida AB -Metodika AB -Carllamm AB -Dialect Uppland AB -Lookpage AB\n",
            "WORK EXPERIENCES 2016/08 - Today (Freelancer) Professional Manager / Documentation designer  | LexDocPharma | Worldwide LexDocPharma aspires to be a ﬁrst-class provider of ready-to-use generic document templates, drawing on years of experience in the European and US medical device and pharmaceutical industries. Our templates are highly ﬂexible and can be adapted to meet the needs of various industries, including traditional herbal medicine and food and beverage. With a focus on ease of use, our goal is to provide high-quality, adaptable templates that streamline the document creation process and save time. 2016/08 - Today (Freelancer) Designer / Developer / Technical support  | Professional freelancer | Worldwide A versatile freelancer with expertise as an IT Coordinator, Designer, Video Presentation Manager, Company Organizer, Quality Manager, and problem-solver with smart solutions. 2013/04 - 2016/08 Designer / Developer    | Lookpage AB | SWE/TRK As an IT Coordinator, I am responsible for providing comprehensive technology support for a business. My duties include purchasing equipment, managing domains, restoring data, and troubleshooting workstations. I have expertise in building and maintaining databases, providing customer support, managing servers, and creating networks. Additionally, I bring skills in graphic presentations and more to the table, making me a well-rounded IT professional. My goal is to ensure the seamless functioning of a company's technology and drive its success. 2010/04 - 2012/02 IT Coordinator & Design Expert | Dialect Uppland AB | SWE During my tenure at Dialect Uppland, I honed my expertise in Mac support, installation, troubleshooting, and fault remediation. I provided both in-person and telephone support for Macs and PCs, working in both the ﬁrst and second line of support. My primary focus was on developing the Mac support function and I earned several certiﬁcates to enhance my skills. In addition to technical support, I was tasked with enhancing the professional appearance of the company's product speciﬁcations and price list, a responsibility that was well received by the company. My goal was to deliver high-quality and efﬁcient technical support, while continually improving the company's Mac project. 2008/02 - 2008/09 IT Technician   | Carllamm AB | SWE \"As an experienced IT and copier repair consultant, I hold certiﬁcations in CompTIA A+ Essentials and IT Technician Essentials, with additional training in SBS 2007 and related courses. I have a proven track record in providing effective solutions for copier repairs, particularly with Richo brand.\" 2007/04 - 2007/08 Developer & Designer | Metodika AB | SWE An initiative to enhance healthcare systems through expert programming and development. 2005/04 - 2006/09 IT Manager  | Custodia AB | SWE I managed the security, upkeep, and availability of the IT systems, including negotiating and purchasing hardware. I continuously sought to improve the functionality and user experience of the computer servers, both PC and Mac. This was a challenging role requiring careful planning and attention to detail. 1999/02 - 2005/04 Quality Technician  | Munkeby Systems AB | SWE I was involved in various aspects of customer service, including technical support, application support, and quality assurance for custom-made products. As a project-focused professional, I was responsible for training customers' staff and ensuring the successful implementation of the company's products. With expertise in HTML, CSS, JavaScript, Dreamweaver MX, XML, PHP , MySQL, and 4th Dimension, I was able to enhance product quality through bug testing and ongoing development. My role also involved traveling and installations within Sweden and various EU countries. 1996/09 - 1996/12 IT Consultant  | IMS AB, Ofﬁce Örestad | SWE T consulting and project management for hardware and software solutions. 1994/01 - 1996/07 Network Technician  | Arena AB | SWE Skilled Network Technician and Manager with expertise in network management and technical support. EDUCATION 2021/09 - 2 days 2021 SAFe® Summit  Get the knowledge and tools you need to improve your SAFe practices, do the  highest-value work, build organizational resilience, and create sustainable change. 2015/08 - 3 days Leadership | Higher diploma  In The Knowledge Era & Business Intelligence Solutions 2012/03 - 4 days Practical Project Management  | Higher diploma   Wenell, Project Management Institute. 2009/02 - 9 month CNC and FMS-operator  | Bachelor's degree  Certiﬁcate Robot Control, KY Education. 2007/04 - 6 month Novell CNA Certiﬁcation | Bachelor's degree  Networking training, Semcon AB,  KY Education  - Novell NetWare  - Windows NT 4.0 Server och Workstation  - Novell NetWare och Windows NT 1998/12 - 2 month Graphic design  | Higher diploma  image and media technology, KY Education.  - Project Methodology  - Web design and graphic design 1998/10 - 2 month Computer Knowledge KY Education | Diploma  - Standard applications, depression, internet and maintenance 1998/08 - 2 month Web design school - KY Education | Higher diploma 1990/08 - 1 year ADB and terminal | Bachelor's degree   work completion for Trade and Business Education Line. 1989/08 - 2 years Trade and Business Education line | Bachelor's degree 1986/08 - 3 years High school 1978/08 - 9 years Elementary school 2008/05 Education in design techniques | Diploma  deploying and managing a network solution. 2008/01  Hardware and software  | Diploma  Training for support and troubleshooting for RICO copy and fax machines  2005/02 4D 2004 developing  | Higher diploma  Developing techniques review of the new version. 2004/11 Developing in PHP & MySQL. | Higher diploma  2003/08 Developing in Javascript course. | Higher diploma 2003/04 4D Web-services i 4D v2003. | Higher diploma  2002/09 Education in Quality | Higher diploma   Assurance at Munkeby Systems AB. 2002/05 Education in Web Server | Higher diploma  4D developing basic TCP / IP communication. 1999/11 Development with 4D 6.5. | Higher diploma  1999/03 4D Development Basics, 4D Sweden AB. | Higher diploma CERTIFICATES 2011/02 Apple Support Professional (ACSP) | Apple Certiﬁed  - Mac OS X Support Essentials v10.6 2011/02 Apple System Administrator (ACSA) | Apple Certiﬁed  - Mac OS X Server Essentials v10.6  - Directory Services v10.6, Deployment v10.6  - Security and Mobility v10.6 2011/03 Apple Technical Coordinator 10.6 | Apple Certiﬁed 2011/06 Apple Specialist Directory Services 10.6. | Apple Certiﬁed 2010/07 Microsoft Technology Specialist (MCTS) | Microsoft Certiﬁed 2010/11 Apple Sales Training Gold certiﬁcate | Apple Certiﬁed 2008/03 CompTia A+ and IT-Technician - Essentials | CompTia A+ 2006/04 Apple Mac OS X server Essentials Certiﬁcate | Apple Certiﬁed 1996/09 ASP Toshiba, repair of laptops | ASP Certiﬁed COMPETENCE  Adobe Photoshop    Adobe Illustrator  Adobe XD  Adobe Premiere   Adobe After Effects   Final Cut Pro   Ofﬁce Suite  Wordpress  PERSONAL QUALIFICATION  Website design  Build online shopping webpages   HTML, CSS, Javascript etc. coding   Logo type creation  Ofﬁce Suite WEBSITE CREATIONS  https://lexdocpharma.com/    https://cksbil.se/  https://wicket.se/  https://cfsnordic.se/\n"
          ]
        }
      ],
      "source": [
        "print(type(text))\n",
        "print(\"_________________________\")\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSyo09QYzdXs",
        "outputId": "2898cfe4-9b91-4e87-bf2e-fdb9815e5e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document = ''.join([i for i in text.split() if i not in stop])\n",
        "sentences = nltk.sent_tokenize(document)"
      ],
      "metadata": {
        "id": "vluaVOoAzTei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [nltk.word_tokenize(sent) for sent in sentences]"
      ],
      "metadata": {
        "id": "7C8_Uvn1z-yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [nltk.pos_tag(sent) for sent in sentences]"
      ],
      "metadata": {
        "id": "YJlSWWMC0C37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    result = sentence.split('/')\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJFxPaTC0OhB",
        "outputId": "87d03398-0157-4d43-bea1-b11cdc43653e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['WORKEXPERIENCE2016-2022ProfessionalManager', 'Designer7y4m2016-2021ITCoordinator', 'Designer6y4m2013-2016Designer', 'Developer3y4m2010-2012ITCoordinator', 'Designer1y10m2008-2008ITconsultantCompTIAA+0y7m2007-2008Developer', 'Designer0y4mKAMALS.M.AHMAD,BORN1972EXPERTINIT&DESIGNSOLUTIONS|WORKEXPERIENCE29YEARSVOLUNTEEREXPERIENCE-ITProjectManager-ProjectCoordinator-NetworkTechnical-Video-editing,ﬁnalcut,adobePremiere,AdobeAftereffects.-4DCinema-PHP,JS,4D,IONIC,-dimension,HTML,CSS-AdobePhotoshop,Illustrator,Indesign.CERTIFICATES-AppleSupportProfessional(ACSP)-AppleSystemAdministrator(ACSA)-AppleCertiﬁedTechnicalCoordinator-AppleCertiﬁedSpecialistDirectoryServices-MicrosoftCertiﬁedTechnologySpecialist(MCTS)-AppleSalesTrainingGoldcertiﬁcate-CompTiaA+EssentialsIT-TechnicianEssentials-AppleMacOSXserverEssentialsCertiﬁcate-ASPCertiﬁedToshiba,repairlaptopsEDUCATION-Leadership-ProjectManagement-NovellCNACertiﬁcation-Web', 'Graphicdesign-ADBterminal-TradeBusiness-Development-QualityEducation-Servereductions-CNCFMS-operatorCOMPETENCE-PHP,Javascript,CSS,HTML-Cinema4d,-Excel,Word,Powerpoint,Outlook,-Pages,Numbers,Mysql-AdobeIllustrator,AdobePhotoshop,AdobeIndesign,FinalcutXPro,Premiere,AdobeEffects,-Ionicmobileapps-4Ddimension,Filemakerproetc.SECTORKNOWLEDGE-DesignWebbdesign-ITCoordinator-ITManager-Banking-Sales-Developing-Media-MarketingINTRUDUCTIONAsseasonedprofessional29yearsexperiencestaffmanagerialrolesacrossinternationalmarketsSweden,Turkey,Jordan,IboastﬂuencySwedish,English,Arabic.IleddeveloperteamsdifferentcountriesbringexpertiseITtechnology,graphicdesign,videoadvertising,smartITsolutions,more.WithbackgroundfrontenddevelopmentusingReactJS,Iwell-versedlatestindustrystandardstechnologies.HoldingcertiﬁcationsITCoordinator,ProjectManager,QualityManager,Iseekingmanagerialpositionutilizeskillsdrivesuccess.ImultipletechnicalcertiﬁcationsincludingAppleSupportProfessional(ACSP),MicrosoftCertiﬁedTechnologySpecialist(MCTS),CompTIAA+Essentialsamongothers,makingwellequippedtacklechallenge.LANGUAGESSwedishProfessionalEnglishElementaryArabicElementaryTECHNICALSKILLSGraphicdesigner11y10mDeveloper10y8mFreelancer6y4mLeadership5y3mProfessionalManager5y1mNetworkadministrator3y3mCNCFMSOperator0y9mPERSONALQUALIFICATIONS-ProfessionalManager-Projectmanager-Consulting-Developing-Designer-Videoedition-SEOSocialMediaWORKEDFOR-ArenaAB-IMSAB-MunkebySystemsAB-CustoidaAB-MetodikaAB-CarllammAB-DialectUpplandAB-LookpageABWORKEXPERIENCES2016', '08-Today(Freelancer)ProfessionalManager', 'Documentationdesigner|LexDocPharma|WorldwideLexDocPharmaaspiresﬁrst-classproviderready-to-usegenericdocumenttemplates,drawingyearsexperienceEuropeanUSmedicaldevicepharmaceuticalindustries.Ourtemplateshighlyﬂexibleadaptedmeetneedsvariousindustries,includingtraditionalherbalmedicinefoodbeverage.Withfocuseaseuse,goalprovidehigh-quality,adaptabletemplatesstreamlinedocumentcreationprocesssavetime.2016', '08-Today(Freelancer)Designer', 'Developer', 'Technicalsupport|Professionalfreelancer|WorldwideAversatilefreelancerexpertiseITCoordinator,Designer,VideoPresentationManager,CompanyOrganizer,QualityManager,problem-solversmartsolutions.2013', '04-2016', '08Designer', 'Developer|LookpageAB|SWE', \"TRKAsITCoordinator,Iresponsibleprovidingcomprehensivetechnologysupportbusiness.Mydutiesincludepurchasingequipment,managingdomains,restoringdata,troubleshootingworkstations.Iexpertisebuildingmaintainingdatabases,providingcustomersupport,managingservers,creatingnetworks.Additionally,Ibringskillsgraphicpresentationstable,makingwell-roundedITprofessional.Mygoalensureseamlessfunctioningcompany'stechnologydrivesuccess.2010\", '04-2012', \"02ITCoordinator&DesignExpert|DialectUpplandAB|SWEDuringtenureDialectUppland,IhonedexpertiseMacsupport,installation,troubleshooting,faultremediation.Iprovidedin-persontelephonesupportMacsPCs,workingﬁrstsecondlinesupport.MyprimaryfocusdevelopingMacsupportfunctionIearnedseveralcertiﬁcatesenhanceskills.Inadditiontechnicalsupport,Itaskedenhancingprofessionalappearancecompany'sproductspeciﬁcationspricelist,responsibilitywellreceivedcompany.Mygoaldeliverhigh-qualityefﬁcienttechnicalsupport,continuallyimprovingcompany'sMacproject.2008\", '02-2008', '09ITTechnician|CarllammAB|SWE\"AsexperiencedITcopierrepairconsultant,IholdcertiﬁcationsCompTIAA+EssentialsITTechnicianEssentials,additionaltrainingSBS2007relatedcourses.Iproventrackrecordprovidingeffectivesolutionscopierrepairs,particularlyRichobrand.']\n",
            "['\"2007', '04-2007', '08Developer&Designer|MetodikaAB|SWEAninitiativeenhancehealthcaresystemsexpertprogrammingdevelopment.2005', '04-2006', '09ITManager|CustodiaAB|SWEImanagedsecurity,upkeep,availabilityITsystems,includingnegotiatingpurchasinghardware.Icontinuouslysoughtimprovefunctionalityuserexperiencecomputerservers,PCMac.Thischallengingrolerequiringcarefulplanningattentiondetail.1999', '02-2005', \"04QualityTechnician|MunkebySystemsAB|SWEIinvolvedvariousaspectscustomerservice,includingtechnicalsupport,applicationsupport,qualityassurancecustom-madeproducts.Asproject-focusedprofessional,Iresponsibletrainingcustomers'staffensuringsuccessfulimplementationcompany'sproducts.WithexpertiseHTML,CSS,JavaScript,DreamweaverMX,XML,PHP,MySQL,4thDimension,Iableenhanceproductqualitybugtestingongoingdevelopment.MyrolealsoinvolvedtravelinginstallationswithinSwedenvariousEUcountries.1996\", '09-1996', '12ITConsultant|IMSAB,OfﬁceÖrestad|SWETconsultingprojectmanagementhardwaresoftwaresolutions.1994', '01-1996', '07NetworkTechnician|ArenaAB|SWESkilledNetworkTechnicianManagerexpertisenetworkmanagementtechnicalsupport.EDUCATION2021', '09-2days2021SAFe®SummitGetknowledgetoolsneedimproveSAFepractices,highest-valuework,buildorganizationalresilience,createsustainablechange.2015', '08-3daysLeadership|HigherdiplomaInTheKnowledgeEra&BusinessIntelligenceSolutions2012', '03-4daysPracticalProjectManagement|HigherdiplomaWenell,ProjectManagementInstitute.2009', \"02-9monthCNCFMS-operator|Bachelor'sdegreeCertiﬁcateRobotControl,KYEducation.2007\", \"04-6monthNovellCNACertiﬁcation|Bachelor'sdegreeNetworkingtraining,SemconAB,KYEducation-NovellNetWare-WindowsNT4.0ServerochWorkstation-NovellNetWareochWindowsNT1998\", '12-2monthGraphicdesign|Higherdiplomaimagemediatechnology,KYEducation.-ProjectMethodology-Webdesigngraphicdesign1998', '10-2monthComputerKnowledgeKYEducation|Diploma-Standardapplications,depression,internetmaintenance1998', '08-2monthWebdesignschool-KYEducation|Higherdiploma1990', \"08-1yearADBterminal|Bachelor'sdegreeworkcompletionTradeBusinessEducationLine.1989\", \"08-2yearsTradeBusinessEducationline|Bachelor'sdegree1986\", '08-3yearsHighschool1978', '08-9yearsElementaryschool2008', '05Educationdesigntechniques|Diplomadeployingmanagingnetworksolution.2008', '01Hardwaresoftware|DiplomaTrainingsupporttroubleshootingRICOcopyfaxmachines2005', '024D2004developing|HigherdiplomaDevelopingtechniquesreviewnewversion.2004', '11DevelopingPHP&MySQL.|Higherdiploma2003', '08DevelopingJavascriptcourse.|Higherdiploma2003', '044DWeb-services4Dv2003.|Higherdiploma2002', '09EducationQuality|HigherdiplomaAssuranceMunkebySystemsAB.2002', '05EducationWebServer|Higherdiploma4DdevelopingbasicTCP', 'IPcommunication.1999', '11Development4D6.5.|Higherdiploma1999', '034DDevelopmentBasics,4DSwedenAB.|HigherdiplomaCERTIFICATES2011', '02AppleSupportProfessional(ACSP)|AppleCertiﬁed-MacOSXSupportEssentialsv10.62011', '02AppleSystemAdministrator(ACSA)|AppleCertiﬁed-MacOSXServerEssentialsv10.6-DirectoryServicesv10.6,Deploymentv10.6-SecurityMobilityv10.62011', '03AppleTechnicalCoordinator10.6|AppleCertiﬁed2011', '06AppleSpecialistDirectoryServices10.6.|AppleCertiﬁed2010', '07MicrosoftTechnologySpecialist(MCTS)|MicrosoftCertiﬁed2010', '11AppleSalesTrainingGoldcertiﬁcate|AppleCertiﬁed2008', '03CompTiaA+IT-Technician-Essentials|CompTiaA+2006', '04AppleMacOSXserverEssentialsCertiﬁcate|AppleCertiﬁed1996', '09ASPToshiba,repairlaptops|ASPCertiﬁedCOMPETENCEAdobePhotoshopAdobeIllustratorAdobeXDAdobePremiereAdobeAfterEffectsFinalCutProOfﬁceSuiteWordpressPERSONALQUALIFICATIONWebsitedesignBuildonlineshoppingwebpagesHTML,CSS,Javascriptetc.codingLogotypecreationOfﬁceSuiteWEBSITECREATIONShttps:', '', 'lexdocpharma.com', 'https:', '', 'cksbil.se', 'https:', '', 'wicket.se', 'https:', '', 'cfsnordic.se', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfcn24utrA99",
        "outputId": "48720ce5-001f-46ad-84c5-cdb45d5f378b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"2007\n",
            "04-2007\n",
            "08Developer&Designer|MetodikaAB|SWEAninitiativeenhancehealthcaresystemsexpertprogrammingdevelopment.2005\n",
            "04-2006\n",
            "09ITManager|CustodiaAB|SWEImanagedsecurity,upkeep,availabilityITsystems,includingnegotiatingpurchasinghardware.\n",
            "Icontinuouslysoughtimprovefunctionalityuserexperiencecomputerservers,PCMac.Thischallengingrolerequiringcarefulplanningattentiondetail.1999\n",
            "02-2005\n",
            "04QualityTechnician|MunkebySystemsAB|SWEIinvolvedvariousaspectscustomerservice,includingtechnicalsupport,applicationsupport,qualityassurancecustom-madeproducts.\n",
            "Asproject-focusedprofessional,Iresponsibletrainingcustomers'staffensuringsuccessfulimplementationcompany'sproducts.\n",
            "WithexpertiseHTML,CSS,JavaScript,DreamweaverMX,XML,PHP,MySQL,4thDimension,Iableenhanceproductqualitybugtestingongoingdevelopment.\n",
            "MyrolealsoinvolvedtravelinginstallationswithinSwedenvariousEUcountries.1996\n",
            "09-1996\n",
            "12ITConsultant|IMSAB,OfﬁceÖrestad|SWETconsultingprojectmanagementhardwaresoftwaresolutions.1994\n",
            "01-1996\n",
            "07NetworkTechnician|ArenaAB|SWESkilledNetworkTechnicianManagerexpertisenetworkmanagementtechnicalsupport.\n",
            "EDUCATION2021\n",
            "09-2days2021SAFe®SummitGetknowledgetoolsneedimproveSAFepractices,highest-valuework,buildorganizationalresilience,createsustainablechange.2015\n",
            "08-3daysLeadership|HigherdiplomaInTheKnowledgeEra&BusinessIntelligenceSolutions2012\n",
            "03-4daysPracticalProjectManagement|HigherdiplomaWenell,ProjectManagementInstitute.2009\n",
            "02-9monthCNCFMS-operator|Bachelor'sdegreeCertiﬁcateRobotControl,KYEducation.2007\n",
            "04-6monthNovellCNACertiﬁcation|Bachelor'sdegreeNetworkingtraining,SemconAB,KYEducation-NovellNetWare-WindowsNT4.0ServerochWorkstation-NovellNetWareochWindowsNT1998\n",
            "12-2monthGraphicdesign|Higherdiplomaimagemediatechnology,KYEducation.-ProjectMethodology-Webdesigngraphicdesign1998\n",
            "10-2monthComputerKnowledgeKYEducation|Diploma-Standardapplications,depression,internetmaintenance1998\n",
            "08-2monthWebdesignschool-KYEducation|Higherdiploma1990\n",
            "08-1yearADBterminal|Bachelor'sdegreeworkcompletionTradeBusinessEducationLine.1989\n",
            "08-2yearsTradeBusinessEducationline|Bachelor'sdegree1986\n",
            "08-3yearsHighschool1978\n",
            "08-9yearsElementaryschool2008\n",
            "05Educationdesigntechniques|Diplomadeployingmanagingnetworksolution.2008\n",
            "01Hardwaresoftware|DiplomaTrainingsupporttroubleshootingRICOcopyfaxmachines2005\n",
            "024D2004developing|HigherdiplomaDevelopingtechniquesreviewnewversion.2004\n",
            "11DevelopingPHP&MySQL.|Higherdiploma2003\n",
            "08DevelopingJavascriptcourse.|Higherdiploma2003\n",
            "044DWeb-services4Dv2003.|Higherdiploma2002\n",
            "09EducationQuality|HigherdiplomaAssuranceMunkebySystemsAB.2002\n",
            "05EducationWebServer|Higherdiploma4DdevelopingbasicTCP\n",
            "IPcommunication.1999\n",
            "11Development4D6.5.|Higherdiploma1999\n",
            "034DDevelopmentBasics,4DSwedenAB.|HigherdiplomaCERTIFICATES2011\n",
            "02AppleSupportProfessional(ACSP)|AppleCertiﬁed-MacOSXSupportEssentialsv10.62011\n",
            "02AppleSystemAdministrator(ACSA)|AppleCertiﬁed-MacOSXServerEssentialsv10.6-DirectoryServicesv10.6,Deploymentv10.6-SecurityMobilityv10.62011\n",
            "03AppleTechnicalCoordinator10.6|AppleCertiﬁed2011\n",
            "06AppleSpecialistDirectoryServices10.6.|AppleCertiﬁed2010\n",
            "07MicrosoftTechnologySpecialist(MCTS)|MicrosoftCertiﬁed2010\n",
            "11AppleSalesTrainingGoldcertiﬁcate|AppleCertiﬁed2008\n",
            "03CompTiaA+IT-Technician-Essentials|CompTiaA+2006\n",
            "04AppleMacOSXserverEssentialsCertiﬁcate|AppleCertiﬁed1996\n",
            "09ASPToshiba,repairlaptops|ASPCertiﬁedCOMPETENCEAdobePhotoshopAdobeIllustratorAdobeXDAdobePremiereAdobeAfterEffectsFinalCutProOfﬁceSuiteWordpressPERSONALQUALIFICATIONWebsitedesignBuildonlineshoppingwebpagesHTML,CSS,Javascriptetc.codingLogotypecreationOfﬁceSuiteWEBSITECREATIONShttps:\n",
            "lexdocpharma.com\n",
            "https:\n",
            "cksbil.se\n",
            "https:\n",
            "wicket.se\n",
            "https:\n",
            "cfsnordic.se\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load English tokenizer, tagger, parser and NER\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "for sentence_result in result:\n",
        "        doc = nlp(sentence_result)\n",
        "\n",
        "        for sent in doc.sents:\n",
        "            output = sent.text\n",
        "            print(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO406M4-2rVH",
        "outputId": "29139de8-ae8a-4d24-baec-a8a52bd00108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrVqKupr6PiW",
        "outputId": "6daffca1-e2ec-4192-97b3-2a5aaf428233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apple True 8.6495 True\n",
            "is True 9.339923 True\n",
            "looking True 7.932023 True\n",
            "at True 7.6291766 True\n",
            "buying True 8.658927 True\n",
            "U.K. True 8.030634 True\n",
            "startup True 6.111695 True\n",
            "for True 8.775849 True\n",
            "$ True 11.222207 True\n",
            "1 True 12.895405 True\n",
            "billion True 9.045538 True\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "# for token in doc:\n",
        "#     print(token.text, token.pos_, token.dep_)\n",
        "\n",
        "# for token in doc:\n",
        "#     print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "#             token.shape_, token.is_alpha, token.is_stop)\n",
        "\n",
        "# for ent in doc.ents:\n",
        "#     print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a-RK8Eb9eCZ",
        "outputId": "6e0c84d8-d42e-4107-c90b-a5ded0d4e7b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I 4690420944186131903 X I I True False True en\n",
            "love 3702023516439754181 xxxx l ove True False False en\n",
            "coffee 3197928453018144401 xxxx c fee True False False en\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"I love coffee\")\n",
        "for word in doc:\n",
        "    lexeme = doc.vocab[word.text]\n",
        "    print(lexeme.text, lexeme.orth, lexeme.shape_, lexeme.prefix_, lexeme.suffix_,\n",
        "            lexeme.is_alpha, lexeme.is_digit, lexeme.is_title, lexeme.lang_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OKgU0878I_7",
        "outputId": "20399ed3-b45d-4108-cf17-e20970f98ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.691649353055761\n",
            "salty fries <-> hamburgers 0.6938489675521851\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")  # make sure to use larger package!\n",
        "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
        "doc2 = nlp(\"Fast food tastes very good.\")\n",
        "\n",
        "# Similarity of two documents\n",
        "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
        "# Similarity of tokens and spans\n",
        "french_fries = doc1[2:4]\n",
        "burgers = doc1[5]\n",
        "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMyoIm0LZq0u",
        "outputId": "d66df0cb-ef11-41d1-e9f5-1fb0b3ab6454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cfsnordic.se\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "doc = nlp(output)\n",
        "\n",
        "# Define regular expression patterns for email and phone\n",
        "phone_pattern = r\"\\b(?:\\d{3}[-.\\s]??\\d{3}[-.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-.\\s]??\\d{4}|\\d{3}[-.\\s]??\\d{4})\\b\"\n",
        "email_pattern = r\"\\b[\\w.-]+@[a-zA-Z]+\\.[a-zA-Z]{2,}\\b\"\n",
        "\n",
        "# Find email addresses and phone numbers using regex\n",
        "phone_numbers = re.findall(phone_pattern, text)\n",
        "emails = re.findall(email_pattern, text)\n",
        "\n",
        "# Replace phone numbers and emails with placeholders in the text\n",
        "for phone_number in phone_numbers:\n",
        "    text = text.replace(phone_number, '')\n",
        "\n",
        "for email in emails:\n",
        "    text = text.replace(email, '')\n",
        "\n",
        "# Initialize variables to store extracted details\n",
        "person_name = \"\"\n",
        "country = \"\"\n",
        "designation = \"\"\n",
        "currency = \"\"\n",
        "other_details = []\n",
        "\n",
        "# Extract named entities and categorize information\n",
        "for entity in doc.ents:\n",
        "    if entity.label_ == \"PERSON\" and not person_name:\n",
        "        person_name = entity.text\n",
        "    elif entity.label_ == \"GPE\" and not country:\n",
        "        country = entity.text\n",
        "    elif entity.label_ == \"MONEY\" and not currency:\n",
        "        currency = entity.text\n",
        "    elif entity.label_ == [\"TITLE\", \"DATE\", \"TIME\"] and not designation:\n",
        "        designation = entity.text\n",
        "\n",
        "\n",
        "# # Display profile information\n",
        "# print(\"*Profile*\")\n",
        "# print(f\"Person Name: {person_name}\")\n",
        "# print(f\"Location: {country}\")\n",
        "# print(f\"Designation: {designation}\")\n",
        "# print(\"Phone: \", phone_number)\n",
        "# print(\"Email: \", email)\n",
        "\n",
        "# Access sentences\n",
        "for sent in doc.sents:\n",
        "    print(sent.text)\n",
        "\n",
        "# Access entities in the document\n",
        "for ent in doc.ents:\n",
        "    print(ent.text,\"      >>>\",ent.label_)\n",
        "\n",
        "# Extract named entities\n",
        "# entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
        "\n",
        "# Display named entities\n",
        "# for entity, label in entities:\n",
        "#     print(f\"Entity: {entity} >>>>> Label: {label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcH_aCBVgTFQ",
        "outputId": "4ec9ec12-055c-40dc-c480-abfdc7d5c575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Profile:\n",
            "Person Name: ['Accomplishments•Developed', 'Marie Claire']\n",
            "Emails: \n",
            "Phone Numbers: \n",
            "Country: Los Angeles\n",
            "Designation: \n"
          ]
        }
      ],
      "source": [
        "# Define regular expression pattern for phone numbers\n",
        "phone_pattern = r\"\\b(?:\\d{3}[-.\\s]??\\d{3}[-.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-.\\s]??\\d{4}|\\d{3}[-.\\s]??\\d{4})\\b\"\n",
        "email_pattern = r\"\\b[\\w.-]+@[a-zA-Z]+\\.[a-zA-Z]{2,}\\b\"\n",
        "\n",
        "# Assume 'pdf_text' contains the text extracted from the PDF\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract emails using SpaCy\n",
        "emails_spacy = [entity.text for entity in doc.ents if entity.label_ == \"EMAIL\"]\n",
        "\n",
        "# Initialize variables to store extracted details\n",
        "person_name = []\n",
        "country = \"\"\n",
        "designation = \"\"\n",
        "other_details = []\n",
        "\n",
        "# Find phone numbers using regex\n",
        "phone_numbers = re.findall(phone_pattern, text)\n",
        "\n",
        "# Use a more refined email regex pattern\n",
        "email_pattern = r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.[\\w\\.]{2,6}\\b\"\n",
        "# Find emails using regex\n",
        "emails_regex = re.findall(email_pattern, text)\n",
        "\n",
        "# Consider emails from SpaCy if available\n",
        "emails = emails_spacy if emails_spacy else emails_regex\n",
        "\n",
        "# Extract other details from SpaCy\n",
        "for entity in doc.ents:\n",
        "    if entity.label_ == \"PERSON\" and \"@\" not in entity.text:\n",
        "        person_name.append(entity.text)\n",
        "    elif entity.label_ == \"GPE\" and not country:\n",
        "        country = entity.text\n",
        "    elif entity.label_ == \"TITLE\" and not designation:\n",
        "        designation = entity.text\n",
        "    # else:\n",
        "    #     other_details.append((entity.text, entity.label_))\n",
        "\n",
        "# Display profile information\n",
        "print(\"Profile:\")\n",
        "print(f\"Person Name: {person_name}\")\n",
        "print(f\"Emails: {', '.join(emails)}\")\n",
        "print(f\"Phone Numbers: {', '.join(phone_numbers)}\")\n",
        "print(f\"Country: {country}\")\n",
        "print(f\"Designation: {designation}\")\n",
        "\n",
        "# Display other details\n",
        "# if other_details:\n",
        "#     print(\"\\nOther Details:\")\n",
        "#     for detail, label in other_details:\n",
        "#         print(f\"{label}: {detail}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JBv0Ca4aNIi",
        "outputId": "40a9239a-75aa-476e-8726-4900ca8d244a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Profile:\n",
            "Person Name: email@email.com\n",
            "MICHELLE\n",
            "Email: \n",
            "Phone: \n",
            "Country: Los Angeles\n",
            "Designation: \n",
            "\n",
            "Other Details:\n",
            "CARDINAL: 1515\n",
            "LOC: Pacific Ave\n",
            "DATE: 90291\n",
            "GPE: United States\n",
            "CARDINAL: 541\n",
            "CARDINAL: 754-3010\n",
            "DATE: 11+ years\n",
            "ORG: Chanel\n",
            "PERSON: Gucci\n",
            "NORP: Designs\n",
            "GPE: Elle\n",
            "ORG: Vogue\n",
            "PRODUCT: fashionista\n",
            "DATE: 2017\n",
            "NORP: Nationality American\n",
            "GPE: San AntonioDriving\n",
            "ORG: Escada\n",
            "GPE: Milan\n",
            "DATE: January 2017\n",
            "DATE: July 2021\n",
            "Functioned\n",
            "DATE: 2019\n",
            "DATE: winter\n",
            "WORK_OF_ART: Associate Fashion Designer\n",
            "PERSON: Dior Homme\n",
            "DATE: January 2014\n",
            "DATE: December 2018\n",
            "CARDINAL: eight\n",
            "ORG: University of Illinois\n",
            "GPE: Chicago\n",
            "DATE: July 2019\n",
            "ORG: •2nd\n",
            "WORK_OF_ART: Best Uniform Design\n",
            "FAC: the Yearly Gallant Show\n",
            "DATE: 2014\n",
            "WORK_OF_ART: Design Theory CAD\n",
            "WORK_OF_ART: Evolution of faux\n"
          ]
        }
      ],
      "source": [
        "# Initialize variables to store extracted details\n",
        "person_name = \"\"\n",
        "email = \"\"\n",
        "phone = \"\"\n",
        "country = \"\"\n",
        "designation = \"\"\n",
        "other_details = []\n",
        "\n",
        "# Extract named entities and categorize information\n",
        "for entity in doc.ents:\n",
        "    if entity.label_ == \"PERSON\" and not person_name:\n",
        "        person_name = entity.text\n",
        "    elif entity.label_ == \"EMAIL\" and not email:\n",
        "        email = entity.text\n",
        "    elif entity.label_ == \"PHONE\" and not phone:\n",
        "        phone = entity.text\n",
        "    elif entity.label_ == \"GPE\" and not country:  # GPE represents geopolitical entities (countries)\n",
        "        country = entity.text\n",
        "    elif entity.label_ == \"TITLE\" and not designation:\n",
        "        designation = entity.text\n",
        "    else:\n",
        "        other_details.append((entity.text, entity.label_))\n",
        "\n",
        "# Display profile information\n",
        "print(\"Profile:\")\n",
        "print(f\"Person Name: {person_name}\")\n",
        "print(f\"Email: {email}\")\n",
        "print(f\"Phone: {phone}\")\n",
        "print(f\"Country: {country}\")\n",
        "print(f\"Designation: {designation}\")\n",
        "\n",
        "# Display other details\n",
        "if other_details:\n",
        "    print(\"\\nOther Details:\")\n",
        "    for detail, label in other_details:\n",
        "        print(f\"{label}: {detail}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQJ-j3QCb58x",
        "outputId": "20640ac5-c576-4940-de11-270171c3f3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Profile:\n",
            "Person Name: email@email.com\n",
            "MICHELLE\n",
            "Emails: email@email.com\n",
            "Phone Numbers: 754-3010\n",
            "Country: Los Angeles\n",
            "Designation: \n",
            "\n",
            "Other Details:\n",
            "90291\n",
            "11+ years\n",
            "Chanel\n",
            "Vogue\n",
            "fashionista\n",
            "2017\n",
            "Escada\n",
            "January 2017\n",
            "July 2021\n",
            "Functioned\n",
            "2019\n",
            "winter\n",
            "January 2014\n",
            "December 2018\n",
            "University of Illinois\n",
            "July 2019\n",
            "•2nd\n",
            "2014\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Define regular expression patterns for email and phone\n",
        "phone_pattern = r\"\\b(?:\\d{3}[-.\\s]??\\d{3}[-.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-.\\s]??\\d{4}|\\d{3}[-.\\s]??\\d{4})\\b\"\n",
        "email_pattern = r\"\\b[\\w.-]+@[a-zA-Z]+\\.[a-zA-Z]{2,}\\b\"\n",
        "\n",
        "# Find email addresses and phone numbers using regex\n",
        "phone_numbers = re.findall(phone_pattern, text)\n",
        "emails = re.findall(email_pattern, text)\n",
        "\n",
        "# Define functions for extraction\n",
        "def extract_entity(doc, label):\n",
        "    return next((entity.text for entity in doc.ents if entity.label_ == label), \"\")\n",
        "\n",
        "def extract_entities(doc, *labels):\n",
        "    return [entity.text for entity in doc.ents if entity.label_ in labels]\n",
        "\n",
        "# Extract specific entities\n",
        "person_name = extract_entity(doc, \"PERSON\")\n",
        "# email = extract_entity(doc, \"EMAIL\")\n",
        "# phone = extract_entity(doc, \"PHONE\")\n",
        "country = extract_entity(doc, \"GPE\")\n",
        "designation = extract_entity(doc, \"TITLE\")\n",
        "\n",
        "# Extract other details\n",
        "other_details = extract_entities(doc, \"ORG\", \"DATE\", \"MONEY\", \"PRODUCT\")\n",
        "\n",
        "# Display profile information\n",
        "print(\"Profile:\")\n",
        "print(f\"Person Name: {person_name}\")\n",
        "print(f\"Emails: {', '.join(emails)}\")\n",
        "print(f\"Phone Numbers: {', '.join(phone_numbers)}\")\n",
        "print(f\"Country: {country}\")\n",
        "print(f\"Designation: {designation}\")\n",
        "\n",
        "# Display other details\n",
        "if other_details:\n",
        "    print(\"\\nOther Details:\")\n",
        "    for detail in other_details:\n",
        "        print(detail)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIFaexRk90uT"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vZjQQIQ9zwJ"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "\n",
        "# Open the PDF file\n",
        "# reader = PdfReader(\"Geneva-Resume-Template-Retro-Simple.pdf\")\n",
        "# reader = PdfReader(\"New-York-Resume-Template-Creative.pdf\")\n",
        "reader = PdfReader(\"Moscow-Creative-Resume-Template.pdf\")\n",
        "\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    text += page.extract_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI78E6Fjz711",
        "outputId": "60ca900e-68f9-40e2-b1c6-0e5b2a7cbb3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"DUSTIN WEST\n",
            "3056478349\n",
            "email@email.com\n",
            "Technical A...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"DUSTIN WEST\n",
            "3056478349\n",
            "email@email.com\n",
            "Technical A...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"DUSTIN WEST\n",
            "3056478349\n",
            "email@email.com\n",
            "Technical A...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"DUSTIN WEST\n",
            "3056478349\n",
            "email@email.com\n",
            "Technical A...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"email@email.com\n",
            " 1515 Pacific Ave, Los Angeles, CA...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"email@email.com\n",
            " 1515 Pacific Ave, Los Angeles, CA...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"email@email.com\n",
            " 1515 Pacific Ave, Los Angeles, CA...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"email@email.com\n",
            " 1515 Pacific Ave, Los Angeles, CA...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"email@email.com\n",
            " 1515 Pacific Ave, Los Angeles, CA...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"email@email.com\n",
            " 1515 Pacific Ave, Los Angeles, CA...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jason Miller\n",
            "Amazon Associate\n",
            "Profile\n",
            "Experienced ...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jason Miller\n",
            "Amazon Associate\n",
            "Profile\n",
            "Experienced ...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jason Miller\n",
            "Amazon Associate\n",
            "Profile\n",
            "Experienced ...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jason Miller\n",
            "Amazon Associate\n",
            "Profile\n",
            "Experienced ...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jason Miller\n",
            "Amazon Associate\n",
            "Profile\n",
            "Experienced ...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jason Miller\n",
            "Amazon Associate\n",
            "Profile\n",
            "Experienced ...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Isabella Johansson\n",
            "Childcare Worker\n",
            "ADDRESS1515 Pa...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Isabella Johansson\n",
            "Childcare Worker\n",
            "ADDRESS1515 Pa...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Isabella Johansson\n",
            "Childcare Worker\n",
            "ADDRESS1515 Pa...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Isabella Johansson\n",
            "Childcare Worker\n",
            "ADDRESS1515 Pa...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Isabella Johansson\n",
            "Childcare Worker\n",
            "ADDRESS1515 Pa...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"JULIE MONROE\n",
            "NUTRITION CONSULTANT\n",
            "D E T A I L S\n",
            "AD...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"JULIE MONROE\n",
            "NUTRITION CONSULTANT\n",
            "D E T A I L S\n",
            "AD...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"JULIE MONROE\n",
            "NUTRITION CONSULTANT\n",
            "D E T A I L S\n",
            "AD...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"JULIE MONROE\n",
            "NUTRITION CONSULTANT\n",
            "D E T A I L S\n",
            "AD...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"JULIE MONROE\n",
            "NUTRITION CONSULTANT\n",
            "D E T A I L S\n",
            "AD...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"JULIE MONROE\n",
            "NUTRITION CONSULTANT\n",
            "D E T A I L S\n",
            "AD...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Esther Scott\n",
            "T R AV E L  A G E N T\n",
            "Details\n",
            "1515 Pa...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Esther Scott\n",
            "T R AV E L  A G E N T\n",
            "Details\n",
            "1515 Pa...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Esther Scott\n",
            "T R AV E L  A G E N T\n",
            "Details\n",
            "1515 Pa...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Esther Scott\n",
            "T R AV E L  A G E N T\n",
            "Details\n",
            "1515 Pa...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mandy Campbell, Bootcamp Instructor\n",
            "1515 Pacific A...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mandy Campbell, Bootcamp Instructor\n",
            "1515 Pacific A...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mandy Campbell, Bootcamp Instructor\n",
            "1515 Pacific A...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mandy Campbell, Bootcamp Instructor\n",
            "1515 Pacific A...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mandy Campbell, Bootcamp Instructor\n",
            "1515 Pacific A...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mandy Campbell, Bootcamp Instructor\n",
            "1515 Pacific A...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"MICHELLE \n",
            "JEWETT\n",
            "Intern\n",
            "Recent Bachelor of Marketi...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"MICHELLE \n",
            "JEWETT\n",
            "Intern\n",
            "Recent Bachelor of Marketi...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"MICHELLE \n",
            "JEWETT\n",
            "Intern\n",
            "Recent Bachelor of Marketi...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"MICHELLE \n",
            "JEWETT\n",
            "Intern\n",
            "Recent Bachelor of Marketi...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"MICHELLE \n",
            "JEWETT\n",
            "Intern\n",
            "Recent Bachelor of Marketi...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"MICHELLE \n",
            "LOPEZ\n",
            "FASHION DESIGNER\n",
            "Expert Fashion De...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"MICHELLE \n",
            "LOPEZ\n",
            "FASHION DESIGNER\n",
            "Expert Fashion De...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"MICHELLE \n",
            "LOPEZ\n",
            "FASHION DESIGNER\n",
            "Expert Fashion De...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"MICHELLE \n",
            "LOPEZ\n",
            "FASHION DESIGNER\n",
            "Expert Fashion De...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"MICHELLE \n",
            "LOPEZ\n",
            "FASHION DESIGNER\n",
            "Expert Fashion De...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mindy Stevenson\n",
            "Occupational Therapist\n",
            "Details\n",
            "Add...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mindy Stevenson\n",
            "Occupational Therapist\n",
            "Details\n",
            "Add...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mindy Stevenson\n",
            "Occupational Therapist\n",
            "Details\n",
            "Add...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mindy Stevenson\n",
            "Occupational Therapist\n",
            "Details\n",
            "Add...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mindy Stevenson\n",
            "Occupational Therapist\n",
            "Details\n",
            "Add...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mindy Stevenson\n",
            "Occupational Therapist\n",
            "Details\n",
            "Add...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Kristen Connelly\n",
            "V I D E O  P R O D U C T  A S S I...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Kristen Connelly\n",
            "V I D E O  P R O D U C T  A S S I...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Kristen Connelly\n",
            "V I D E O  P R O D U C T  A S S I...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Kristen Connelly\n",
            "V I D E O  P R O D U C T  A S S I...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Kristen Connelly\n",
            "V I D E O  P R O D U C T  A S S I...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Kristen Connelly\n",
            "V I D E O  P R O D U C T  A S S I...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Janine Nel\n",
            "Sales Engineer\n",
            "1515 Pacific Ave, Los An...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Janine Nel\n",
            "Sales Engineer\n",
            "1515 Pacific Ave, Los An...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Janine Nel\n",
            "Sales Engineer\n",
            "1515 Pacific Ave, Los An...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Janine Nel\n",
            "Sales Engineer\n",
            "1515 Pacific Ave, Los An...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Janine Nel\n",
            "Sales Engineer\n",
            "1515 Pacific Ave, Los An...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Janine Nel\n",
            "Sales Engineer\n",
            "1515 Pacific Ave, Los An...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"ROBERT COOPER\n",
            "SECURITY GUARD\n",
            "LOS ANGELES, CA 90291...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"ROBERT COOPER\n",
            "SECURITY GUARD\n",
            "LOS ANGELES, CA 90291...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"ROBERT COOPER\n",
            "SECURITY GUARD\n",
            "LOS ANGELES, CA 90291...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"ROBERT COOPER\n",
            "SECURITY GUARD\n",
            "LOS ANGELES, CA 90291...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"ROBERT COOPER\n",
            "SECURITY GUARD\n",
            "LOS ANGELES, CA 90291...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"ROBERT COOPER\n",
            "SECURITY GUARD\n",
            "LOS ANGELES, CA 90291...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1515 Pacific Ave, Los Angeles, CA 90291, United St...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1515 Pacific Ave, Los Angeles, CA 90291, United St...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1515 Pacific Ave, Los Angeles, CA 90291, United St...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1515 Pacific Ave, Los Angeles, CA 90291, United St...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1515 Pacific Ave, Los Angeles, CA 90291, United St...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1515 Pacific Ave, Los Angeles, CA 90291, United St...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"LAYNEY SPENCER\n",
            "Assistant Director\n",
            "1515 Pacific Ave...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"LAYNEY SPENCER\n",
            "Assistant Director\n",
            "1515 Pacific Ave...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"LAYNEY SPENCER\n",
            "Assistant Director\n",
            "1515 Pacific Ave...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"LAYNEY SPENCER\n",
            "Assistant Director\n",
            "1515 Pacific Ave...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"LAYNEY SPENCER\n",
            "Assistant Director\n",
            "1515 Pacific Ave...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"LAYNEY SPENCER\n",
            "Assistant Director\n",
            "1515 Pacific Ave...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SHERRI\n",
            "PRICE\n",
            "Event Coordinator\n",
            "D E TA I L S\n",
            "Contac...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SHERRI\n",
            "PRICE\n",
            "Event Coordinator\n",
            "D E TA I L S\n",
            "Contac...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SHERRI\n",
            "PRICE\n",
            "Event Coordinator\n",
            "D E TA I L S\n",
            "Contac...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SHERRI\n",
            "PRICE\n",
            "Event Coordinator\n",
            "D E TA I L S\n",
            "Contac...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SHERRI\n",
            "PRICE\n",
            "Event Coordinator\n",
            "D E TA I L S\n",
            "Contac...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SHERRI\n",
            "PRICE\n",
            "Event Coordinator\n",
            "D E TA I L S\n",
            "Contac...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"GENE HOFFMAN\n",
            "Bar Manageremail@email.com\n",
            "3868683442...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"GENE HOFFMAN\n",
            "Bar Manageremail@email.com\n",
            "3868683442...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"GENE HOFFMAN\n",
            "Bar Manageremail@email.com\n",
            "3868683442...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"GENE HOFFMAN\n",
            "Bar Manageremail@email.com\n",
            "3868683442...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"GENE HOFFMAN\n",
            "Bar Manageremail@email.com\n",
            "3868683442...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"GENE HOFFMAN\n",
            "Bar Manageremail@email.com\n",
            "3868683442...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1Marketing Assistant 1515 Pacific Ave, Los Angeles...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1Marketing Assistant 1515 Pacific Ave, Los Angeles...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1Marketing Assistant 1515 Pacific Ave, Los Angeles...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1Marketing Assistant 1515 Pacific Ave, Los Angeles...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1Marketing Assistant 1515 Pacific Ave, Los Angeles...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"1Marketing Assistant 1515 Pacific Ave, Los Angeles...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Howard Wright\n",
            "W E L L N E S S  C O A C H\n",
            "email@ema...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Howard Wright\n",
            "W E L L N E S S  C O A C H\n",
            "email@ema...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Howard Wright\n",
            "W E L L N E S S  C O A C H\n",
            "email@ema...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Howard Wright\n",
            "W E L L N E S S  C O A C H\n",
            "email@ema...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Sumeet Shadev        \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  Professional Pro...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Sumeet Shadev        \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  Professional Pro...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Sumeet Shadev        \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  Professional Pro...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Sumeet Shadev        \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  Professional Pro...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Sumeet Shadev        \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  Professional Pro...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Sumeet Shadev        \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  Professional Pro...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SEAN\n",
            "PRICE\n",
            "IT Consultant\n",
            "DETAILS\n",
            "ADDRESS\n",
            "1515 Paci...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SEAN\n",
            "PRICE\n",
            "IT Consultant\n",
            "DETAILS\n",
            "ADDRESS\n",
            "1515 Paci...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SEAN\n",
            "PRICE\n",
            "IT Consultant\n",
            "DETAILS\n",
            "ADDRESS\n",
            "1515 Paci...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SEAN\n",
            "PRICE\n",
            "IT Consultant\n",
            "DETAILS\n",
            "ADDRESS\n",
            "1515 Paci...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SEAN\n",
            "PRICE\n",
            "IT Consultant\n",
            "DETAILS\n",
            "ADDRESS\n",
            "1515 Paci...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SEAN\n",
            "PRICE\n",
            "IT Consultant\n",
            "DETAILS\n",
            "ADDRESS\n",
            "1515 Paci...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Julie Bridges\n",
            "YO GA  T E AC H E R\n",
            "38686834421515 P...\" with entities \"[(0, 8, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Julie Bridges\n",
            "YO GA  T E AC H E R\n",
            "38686834421515 P...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Julie Bridges\n",
            "YO GA  T E AC H E R\n",
            "38686834421515 P...\" with entities \"[(9, 34, 'ADDRESS')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Julie Bridges\n",
            "YO GA  T E AC H E R\n",
            "38686834421515 P...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Julie Bridges\n",
            "YO GA  T E AC H E R\n",
            "38686834421515 P...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Julie Bridges\n",
            "YO GA  T E AC H E R\n",
            "38686834421515 P...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jennifer Adams, Project \n",
            "Assistant\n",
            "1515 PACIFIC A ...\" with entities \"[(7, 23, 'EMAIL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jennifer Adams, Project \n",
            "Assistant\n",
            "1515 PACIFIC A ...\" with entities \"[(7, 23, 'PHONE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jennifer Adams, Project \n",
            "Assistant\n",
            "1515 PACIFIC A ...\" with entities \"[(17, 35, 'JOB_TITLE'), (39, 46, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jennifer Adams, Project \n",
            "Assistant\n",
            "1515 PACIFIC A ...\" with entities \"[(8, 14, 'SKILL'), (16, 32, 'SKILL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "from PyPDF2 import PdfReader\n",
        "import os\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract text from a PDF file.\n",
        "    Args:\n",
        "    - pdf_path (str): Path to the PDF file.\n",
        "    Returns:\n",
        "    - str: Extracted text from the PDF.\n",
        "    \"\"\"\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Create a blank English model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "training_data = [\n",
        "    (\"John Doe\", {\"entities\": [(0, 8, \"NAME\")]}),\n",
        "    (\"Email: john@example.com\", {\"entities\": [(7, 23, \"EMAIL\")]}),\n",
        "    (\"Address: 123 Main St, City, Country\", {\"entities\": [(9, 34, \"ADDRESS\")]}),\n",
        "    (\"Phone: (123) 456-7890\", {\"entities\": [(7, 23, \"PHONE\")]}),\n",
        "    (\"Work Experience: Software Engineer at XYZ Inc.\", {\"entities\": [(17, 35, \"JOB_TITLE\"), (39, 46, \"ORG\")]}),\n",
        "    (\"Skills: Python, Machine Learning\", {\"entities\": [(8, 14, \"SKILL\"), (16, 32, \"SKILL\")]}),\n",
        "    # Add more annotated samples here\n",
        "]\n",
        "\n",
        "\n",
        "# Process the extracted text with SpaCy and train the model\n",
        "folder_path = \"/content/\"\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(folder_path, filename)\n",
        "        resume_text = extract_text_from_pdf(pdf_path)  # Function to extract text from PDF\n",
        "\n",
        "        # Create Example objects from the training data\n",
        "        for text, annotations in training_data:\n",
        "            example = Example.from_dict(nlp.make_doc(resume_text), annotations)\n",
        "            nlp.update([example], losses={})  # Update the model weights\n",
        "\n",
        "# Save the trained model\n",
        "nlp.to_disk(\"/content/trained_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3UAw5hs92o8"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "nlp.to_disk(\"/content/me\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXJYmbeq-TWE",
        "outputId": "83b1cba3-0cbe-4e96-ddd6-ac8ae5e1306a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x78768ab4ed40>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the model from the directory where it was saved\n",
        "nlp = spacy.load(\"/content/trained_model\")  # If it's a complete model\n",
        "\n",
        "# Or, if it's an empty model that needs to be populated\n",
        "nlp = spacy.blank(\"en\")  # Replace \"en\" with the language code if it's a different language\n",
        "nlp.from_disk(\"/content/trained_model\")  # Load model components from the directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjfihM17ADcE"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the saved model\n",
        "nlp = spacy.load(\"/content/trained_model\")  # Replace with your model path\n",
        "\n",
        "# Process whole documents\n",
        "# text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
        "#         \"Google in 2007, few people outside of the company took him \"\n",
        "#         \"Email: hassanqureshi700@gmail.com \"\n",
        "#         \"Phone: 0321-2712753 \"\n",
        "#         \"Designation: AI Engineer. \"\n",
        "#         \"Name: Adam \"\n",
        "#         \"US, San Francisco \"\n",
        "#         \"Skills: Python, Designing, Cooking \"\n",
        "#         \"Work Experience: 2 Years \"\n",
        "#         \"Employment History: Bytewise Ltd \"\n",
        "#         \"Position: Deep Learning Fellow \"\n",
        "#         \"seriously. “I can tell you very senior CEOs of major American \"\n",
        "#         \"car companies would shake my hand and turn away because I wasn’t \"\n",
        "#         \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
        "#         \"this week.\")\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "\n",
        "# Open the PDF file\n",
        "# reader = PdfReader(\"Geneva-Resume-Template-Retro-Simple.pdf\")\n",
        "reader = PdfReader(\"New-York-Resume-Template-Creative.pdf\")\n",
        "# reader = PdfReader(\"Moscow-Creative-Resume-Template.pdf\")\n",
        "\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    text += page.extract_text()\n",
        "\n",
        "# Process the text using the loaded model\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract named entities\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n",
        "\n",
        "# Analyze syntax\n",
        "# for token in doc:\n",
        "#     print(token.text, token.lemma_, token.pos_, token.dep_)\n",
        "\n",
        "# Access sentences\n",
        "# for sent in doc.sents:\n",
        "#     sentences = print(sent.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD8iet8e_6HV",
        "outputId": "c705514e-b778-4a2b-cd57-fc5079801d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Load the trained model\n",
        "nlp = spacy.load(\"/content/trained_model\")  # Replace with your model path\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract text from a PDF file.\n",
        "    Args:\n",
        "    - pdf_path (str): Path to the PDF file.\n",
        "    Returns:\n",
        "    - str: Extracted text from the PDF.\n",
        "    \"\"\"\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def extract_entities_from_resume(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract entities from a resume PDF using the trained model.\n",
        "    Args:\n",
        "    - pdf_path (str): Path to the resume PDF file.\n",
        "    Returns:\n",
        "    - list: Extracted entities with their labels.\n",
        "    \"\"\"\n",
        "    resume_text = extract_text_from_pdf(pdf_path)\n",
        "    doc = nlp(resume_text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "# Example usage:\n",
        "pdf_resume_path = \"/content/Cape-Town-Resume-Template-Retro-Creative.pdf\"  # Replace with your resume path\n",
        "extracted_entities = extract_entities_from_resume(pdf_resume_path)\n",
        "print(extracted_entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy4fXb1cBPUT"
      },
      "source": [
        "# **CV Summarization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY4_FiE1BNsy",
        "outputId": "aa6683a1-c7cc-489f-fc54-f4e55a5ebcdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
              " {'entities': [(1749, 1755, 'Companies worked at'),\n",
              "   (1696, 1702, 'Companies worked at'),\n",
              "   (1417, 1423, 'Companies worked at'),\n",
              "   (1356, 1793, 'Skills'),\n",
              "   (1209, 1215, 'Companies worked at'),\n",
              "   (1136, 1248, 'Skills'),\n",
              "   (928, 932, 'Graduation Year'),\n",
              "   (858, 889, 'College Name'),\n",
              "   (821, 856, 'Degree'),\n",
              "   (787, 791, 'Graduation Year'),\n",
              "   (744, 750, 'Companies worked at'),\n",
              "   (722, 742, 'Designation'),\n",
              "   (658, 664, 'Companies worked at'),\n",
              "   (640, 656, 'Designation'),\n",
              "   (574, 580, 'Companies worked at'),\n",
              "   (555, 573, 'Designation'),\n",
              "   (470, 493, 'Companies worked at'),\n",
              "   (444, 469, 'Designation'),\n",
              "   (308, 314, 'Companies worked at'),\n",
              "   (234, 240, 'Companies worked at'),\n",
              "   (175, 198, 'Companies worked at'),\n",
              "   (93, 137, 'Email Address'),\n",
              "   (39, 48, 'Location'),\n",
              "   (13, 38, 'Designation'),\n",
              "   (0, 12, 'Name')]})"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "\n",
        "train_data = pickle.load(open('train_data.pkl', 'rb'))\n",
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsjSftXiBqlj"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.blank('en')\n",
        "\n",
        "def train_model(train_data):\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe(ner, last = True)\n",
        "\n",
        "    for _, annotation in train_data:\n",
        "        for ent in annotation['entities']:\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(10):\n",
        "            print(\"Statring iteration \" + str(itn))\n",
        "            random.shuffle(train_data)\n",
        "            losses = {}\n",
        "            index = 0\n",
        "            for text, annotations in train_data:\n",
        "                try:\n",
        "                    nlp.update(\n",
        "                        [text],  # batch of texts\n",
        "                        [annotations],  # batch of annotations\n",
        "                        drop=0.2,  # dropout - make it harder to memorise data\n",
        "                        sgd=optimizer,  # callable to update weights\n",
        "                        losses=losses)\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "\n",
        "            print(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nhpn4G9JBxba"
      },
      "outputs": [],
      "source": [
        "def train_model(nlp, train_data):\n",
        "  \"\"\"Trains a spaCy model on the given data.\"\"\"\n",
        "\n",
        "  if 'ner' not in nlp.pipe_names:\n",
        "    ner = nlp.create_pipe('ner')\n",
        "    nlp.add_pipe(ner, last=True)\n",
        "\n",
        "  for _, annotation in train_data:\n",
        "    ner.add_label(annotation['label'])\n",
        "\n",
        "  nlp.begin_training()\n",
        "  for batch in train_data:\n",
        "    nlp.update(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yrGEyViCPlh"
      },
      "outputs": [],
      "source": [
        "nlp.to_disk('nlp_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "Jd8qybvdCU_G",
        "outputId": "66871419-245e-41c9-98d4-b2c0fe4225b5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/'"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp_model = spacy.load('nlp_model')\n",
        "train_data[0][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS4Sf0CVCb3c"
      },
      "outputs": [],
      "source": [
        "doc = nlp_model(train_data[0][0])\n",
        "for ent in doc.ents:\n",
        "    print(f'{ent.label_.upper():{30}}- {ent.text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4dMfz8HCnW-",
        "outputId": "975715e3-a911-4b06-aca8-ae027298db81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.8-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.7 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.8 PyMuPDFb-1.23.7\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ffv8K684ClEX"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "pf\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract text from a PDF file.\n",
        "    Args:\n",
        "    - pdf_path (str): Path to the PDF file.\n",
        "    Returns:\n",
        "    - str: Extracted text from the PDF.\n",
        "    \"\"\"\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IYBJm9H5CuYl",
        "outputId": "dd72f49b-2382-405c-db39-f9b455692fb5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tx' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-5dde4c819b40>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{ent.label_.upper():{30}}- {ent.text}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tx' is not defined"
          ]
        }
      ],
      "source": [
        "doc = nlp_model(tx)\n",
        "for ent in doc.ents:\n",
        "    print(f'{ent.label_.upper():{30}}- {ent.text}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XL2w72Tx4I-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Resume Parser**"
      ],
      "metadata": {
        "id": "I-0-yu1l4Jkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install pyproject-toml\n",
        "!pip install spacy==2.3.5\n",
        "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
        "!pip install pyresparser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1ZoYlNW4M3p",
        "outputId": "2883a742-67ab-40a5-e18b-21d65432d382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Collecting pyproject-toml\n",
            "  Downloading pyproject_toml-0.0.10-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.10/dist-packages (from pyproject-toml) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from pyproject-toml) (0.42.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pyproject-toml) (0.10.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from pyproject-toml) (4.19.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->pyproject-toml) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->pyproject-toml) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->pyproject-toml) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->pyproject-toml) (0.15.2)\n",
            "Installing collected packages: pyproject-toml\n",
            "Successfully installed pyproject-toml-0.0.10\n",
            "Collecting spacy==2.3.5\n",
            "  Using cached spacy-2.3.5.tar.gz (5.8 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (3.0.9)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (7.4.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (0.10.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (1.0.7)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (4.66.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (67.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (1.23.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==2.3.5) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2023.11.17)\n",
            "Building wheels for collected packages: spacy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for spacy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for spacy (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for spacy\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build spacy\n",
            "\u001b[31mERROR: Could not build wheels for spacy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==2.3.1) (2.3.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (7.4.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (0.10.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.7)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (4.66.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (67.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.23.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2023.11.17)\n",
            "Requirement already satisfied: pyresparser in /usr/local/lib/python3.10/dist-packages (1.0.6)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (23.1.0)\n",
            "Requirement already satisfied: blis>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (0.7.11)\n",
            "Requirement already satisfied: certifi>=2019.6.16 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2023.11.17)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (5.2.0)\n",
            "Requirement already satisfied: cymem>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.0.8)\n",
            "Requirement already satisfied: docx2txt>=0.7 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (0.8)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.6)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (4.19.2)\n",
            "Requirement already satisfied: nltk>=3.4.3 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.5.3)\n",
            "Requirement already satisfied: pdfminer.six>=20181108 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (20231228)\n",
            "Requirement already satisfied: preshed>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.0.9)\n",
            "Requirement already satisfied: pycryptodome>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (3.19.1)\n",
            "Requirement already satisfied: pyrsistent>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (0.20.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2019.1 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2023.3.post1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.31.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.16.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.4.0)\n",
            "Requirement already satisfied: spacy>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.3.9)\n",
            "Requirement already satisfied: srsly>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (1.0.7)\n",
            "Requirement already satisfied: thinc>=7.0.4 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (7.4.6)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (4.66.1)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (2.0.7)\n",
            "Requirement already satisfied: wasabi>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from pyresparser) (0.10.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0.1->pyresparser) (0.15.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4.3->pyresparser) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20181108->pyresparser) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20181108->pyresparser) (41.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from preshed>=2.0.1->pyresparser) (1.0.10)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (67.7.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.4->pyresparser) (1.1.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmHBXYWK4uN8",
        "outputId": "eac465c2-ad80-44e4-bd71-234e0f0bb312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyresparser import ResumeParser\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "data = ResumeParser(\"/content/Geneva-Resume-Template-Retro-Simple.pdf\").get_extracted_data()\n",
        "\n",
        "\n",
        "print(\"Name:\", data[\"name\"])\n",
        "print(\"Email:\", data[\"email\"])\n",
        "print(\"Mobile Number:\", data[\"mobile_number\"])\n",
        "print(\"Skills:\", data[\"skills\"])\n",
        "print(\"College Name:\", data[\"college_name\"])\n",
        "print(\"Degree:\", data[\"degree\"])\n",
        "print(\"Designation:\", data[\"designation\"])\n",
        "print(\"Company Names:\", data[\"company_names\"])\n",
        "print(\"No Of Pages:\", data[\"no_of_pages\"])\n",
        "print(\"Total Experience:\", data[\"total_experience\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "nQhyGJiY4h8n",
        "outputId": "0108af36-af98-435c-f4fd-8d125d4753e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[E053] Could not read config file from /usr/local/lib/python3.10/dist-packages/en_core_web_sm/en_core_web_sm-2.3.1/config.cfg",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-36bd9fd1d1a6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResumeParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Geneva-Resume-Template-Retro-Simple.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extracted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexpand_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \"\"\"Find string in tokenizer exceptions, duplicate entry and replace string.\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mstop\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/en_core_web_sm/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_config\u001b[0;34m(path, overrides, interpolate)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"&amp;\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"&lt;\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"&gt;\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"&quot;\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E053] Could not read config file from /usr/local/lib/python3.10/dist-packages/en_core_web_sm/en_core_web_sm-2.3.1/config.cfg"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}